{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10b31817",
   "metadata": {},
   "source": [
    "# Prerequisites\n",
    "\n",
    "Please run `01_data_exploration.ipynb` before running this notebook as it uses the output of data exploration.\n",
    "\n",
    "## Dataset Requirements\n",
    "\n",
    "- `metadata_updated.csv` must be stored in `data` folder in your project root directory\n",
    "- Images must be stored in the `data/raw_dataset` folder\n",
    "- Expected structure:\n",
    "  - `data/metadata_updated.csv` - Updated metadata file\n",
    "  - `data/raw_dataset/images/` - Contains all dermatological images\n",
    "\n",
    "## Notebook Structure\n",
    "\n",
    "This notebook follows a structured workflow:\n",
    "- Loading required libraries\n",
    "- Defining constants and paths\n",
    "- Splitting data into training (60%), validation (20%), and testing sets (20%) using stratified sampling\n",
    "- Creating custom PyTorch dataset class for skin lesion images\n",
    "- Implementing data transformation pipelines for training and validation/testing\n",
    "- Applying data augmentation techniques to increase dataset diversity\n",
    "- Creating and storing processed datasets as PyTorch tensors for efficient model training\n",
    "\n",
    "## Outputs\n",
    "\n",
    "This notebook provides the following outputs:\n",
    "- Augmented images inside `data/augmented_images` folder\n",
    "- Processed datasets `train_dataset.pt`, `val_dataset.pt` and `test_dataset.pt` inside `data/processed` folder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e9be021",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e2d6a7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dango\\OneDrive - UWE Bristol\\projects\\thesis-project\\venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# System libraries\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Third-party libraries\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "# Local imports\n",
    "from scd.utils.common import get_test_transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94e3c323",
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8774769f",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 42\n",
    "\n",
    "# Define paths\n",
    "root_dir = Path.cwd().parent\n",
    "data_dir = root_dir / 'data'\n",
    "image_path = data_dir / 'raw_dataset' / 'images'\n",
    "augmented_image_path = data_dir / 'augmented_images'\n",
    "metadata_path = data_dir / 'metadata_updated.csv'\n",
    "processed_data_dir = data_dir / 'processed'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e79293f6",
   "metadata": {},
   "source": [
    "# Load Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "54cfae54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>DDI_ID</th>\n",
       "      <th>image_id</th>\n",
       "      <th>skin_tone</th>\n",
       "      <th>malignant</th>\n",
       "      <th>disease</th>\n",
       "      <th>strata</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>000001.png</td>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>melanoma-in-situ</td>\n",
       "      <td>56_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>000002.png</td>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>melanoma-in-situ</td>\n",
       "      <td>56_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>000003.png</td>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>mycosis-fungoides</td>\n",
       "      <td>56_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>000004.png</td>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>squamous-cell-carcinoma-in-situ</td>\n",
       "      <td>56_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>000005.png</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>basal-cell-carcinoma</td>\n",
       "      <td>12_1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  DDI_ID    image_id  skin_tone  malignant  \\\n",
       "0           0       1  000001.png         56          1   \n",
       "1           1       2  000002.png         56          1   \n",
       "2           2       3  000003.png         56          1   \n",
       "3           3       4  000004.png         56          1   \n",
       "4           4       5  000005.png         12          1   \n",
       "\n",
       "                           disease strata  \n",
       "0                 melanoma-in-situ   56_1  \n",
       "1                 melanoma-in-situ   56_1  \n",
       "2                mycosis-fungoides   56_1  \n",
       "3  squamous-cell-carcinoma-in-situ   56_1  \n",
       "4             basal-cell-carcinoma   12_1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load metadata\n",
    "metadata = pd.read_csv(metadata_path)\n",
    "metadata.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd280c24",
   "metadata": {},
   "source": [
    "# Split Training, Validation and Testing Set\n",
    "\n",
    "We split the dataset into training (60%), validation (20%) and testing (20%) sets using stratified sampling to ensure balanced distribution of malignant and benign cases across all skin tones. This approach maintains the same proportion of classes in each subset, which is important for model training and evaluation, especially with imbalanced datasets.\n",
    "\n",
    "We first split the data into train (60%) and a temporary set (40%), then further divide the temporary set into validation and test sets of equal size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "771cee02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training, validation, and test sets\n",
    "train_df, val_df = train_test_split(\n",
    "  metadata, \n",
    "  test_size=0.4, \n",
    "  stratify=metadata['malignant'], \n",
    "  random_state=random_state\n",
    ")\n",
    "\n",
    "val_df, test_df = train_test_split(\n",
    "  val_df,\n",
    "  test_size=0.5,\n",
    "  stratify=val_df['malignant'],\n",
    "  random_state=random_state\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a9879ec",
   "metadata": {},
   "source": [
    "# Prepare Dataset\n",
    "\n",
    "We create a custom PyTorch dataset class (`SkinDataset`) to efficiently load and preprocess skin lesion images for our deep learning model. The dataset class handles:\n",
    "\n",
    "1. Loading images from file paths using data stored in our metadata DataFrame\n",
    "2. Applying provided transformations to the images\n",
    "3. Pairing each image with its corresponding label (malignant or benign) and filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f97e186a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SkinDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Custom Dataset for loading skin images and their labels.\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, dataframe: pd.DataFrame, data_dir: str, transform: callable):\n",
    "        \"\"\"\n",
    "        Initializes the SkinDataset with a DataFrame, data directory, and transformations.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        dataframe : pandas.DataFrame\n",
    "            DataFrame containing image file names and labels.\n",
    "        data_dir : str\n",
    "            Directory where raw and augmented images are stored.\n",
    "        transform : callable\n",
    "            Transformations to apply to the images.\n",
    "        \"\"\"\n",
    "        self.dataframe = dataframe.reset_index(drop=True)\n",
    "        self.raw_dataset_path = data_dir / 'raw_dataset' / 'images'\n",
    "        self.aug_dataset_path = data_dir / 'augmented_images'\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        \"\"\" \n",
    "        Returns the number of samples in the dataset. \n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        int\n",
    "            Number of samples in the dataset.\n",
    "        \"\"\"\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx: int) -> tuple:\n",
    "        \"\"\"\n",
    "        Retrieves an image and its label by index.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        idx : int\n",
    "            Index of the sample to retrieve.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        tuple\n",
    "            A tuple containing the transformed image and its label.\n",
    "        \"\"\"\n",
    "        # Create image path with image directory and filename\n",
    "        filename = str(self.dataframe.loc[idx, 'image_id'])\n",
    "        if 'aug' in filename:\n",
    "            img_path = os.path.join(self.aug_dataset_path, filename) # use augmented images path\n",
    "        else:\n",
    "            img_path = os.path.join(self.raw_dataset_path, filename) # use raw images path\n",
    "        \n",
    "        # Retrieve the label for the image\n",
    "        label = self.dataframe.loc[idx, 'malignant']\n",
    "\n",
    "        # Load the image, convert to RGB, and apply transformations\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        image_np = np.array(image)\n",
    "        image = self.transform(image=image_np)['image']\n",
    "\n",
    "        # Return the transformed image and its label and filename\n",
    "        return image, label, filename\n",
    "    \n",
    "    def get_labels(self) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Returns the labels of the dataset.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        numpy.ndarray\n",
    "            Array of labels.\n",
    "        \"\"\"\n",
    "        return self.dataframe['malignant'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba2b1197",
   "metadata": {},
   "source": [
    "# Data Transformation\n",
    "\n",
    "The `transformation()` function creates different transformation pipelines:\n",
    "\n",
    "1. **Training Transformations:** Apply various random modifications to training images to help the model learn more robust features:\n",
    "  - Resize images to provided size\n",
    "  - Random horizontal and vertical flips to simulate different orientations\n",
    "  - Random affine transformations (rotation, translation, scaling) to provide positional variance\n",
    "  - Color jitter to simulate lighting variations\n",
    "  - Gaussian blur to simulate focus variations in dermatoscopic images\n",
    "  - Random erasing to help the model learn to identify lesions even with partial occlusions\n",
    "  - Normalisation with ImageNet mean and standard deviation values\n",
    "\n",
    "2. **Augmentation Transformations:** Similar to training transformations but without normalisation and tensor conversion, specifically designed for generating new training examples:\n",
    "  - All the same transformations as training pipeline\n",
    "  - Outputs numpy arrays instead of tensors for direct saving to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "18f8ed78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformations(resize: tuple, for_augmentation: bool =False) -> A.Compose:\n",
    "    \"\"\"\n",
    "    Creates a set of transformations for training or augmentation.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    resize : tuple\n",
    "        Target size in (height, width) format.\n",
    "    for_augmentation : bool\n",
    "        If True, returns only the training transformation for augmentation purposes.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    albumentations.Compose\n",
    "        The augmentation or training transformations.\n",
    "    \"\"\"\n",
    "    if for_augmentation:\n",
    "        # If for augmentation, only return the training transform\n",
    "        return A.Compose([\n",
    "            A.Resize(height=resize[0], width=resize[1]),\n",
    "            A.HorizontalFlip(p=0.2),\n",
    "            A.VerticalFlip(p=0.2),\n",
    "            A.Affine(rotate=(-20, 20), translate_percent=(0.1, 0.1), scale=(0.9, 1.1), p=0.8),\n",
    "            A.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.0, p=0.5),\n",
    "            A.GaussianBlur(blur_limit=(5, 5), sigma_limit=(0.1, 2.0), p=0.3),\n",
    "            A.CoarseDropout(\n",
    "                num_holes_range=(1, 8),\n",
    "                hole_height_range=(int(resize[0]*0.05), int(resize[0]*0.1)),\n",
    "                hole_width_range=(int(resize[1]*0.05), int(resize[1]*0.1)),\n",
    "                fill=0,\n",
    "                p=0.2\n",
    "            ),\n",
    "        ])\n",
    "\n",
    "    # Define the training transformation pipeline\n",
    "    train_transform = A.Compose([\n",
    "        A.Resize(height=resize[0], width=resize[1]),\n",
    "        A.HorizontalFlip(p=0.2),\n",
    "        A.VerticalFlip(p=0.2),\n",
    "        A.Affine(rotate=(-20, 20), translate_percent=(0.1, 0.1), scale=(0.9, 1.1), p=0.8),\n",
    "        A.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.0, p=0.5),\n",
    "        A.GaussianBlur(blur_limit=(5, 5), sigma_limit=(0.1, 2.0), p=0.3),\n",
    "        A.CoarseDropout(\n",
    "            num_holes_range=(1, 8),\n",
    "            hole_height_range=(int(resize[0]*0.05), int(resize[0]*0.1)),\n",
    "            hole_width_range=(int(resize[1]*0.05), int(resize[1]*0.1)),\n",
    "            fill=0,\n",
    "            p=0.2\n",
    "        ),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) if not for_augmentation else lambda x: x,\n",
    "        ToTensorV2() if not for_augmentation else lambda x: x,\n",
    "    ])\n",
    "\n",
    "    return train_transform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d995b5c6",
   "metadata": {},
   "source": [
    "# Data Augmentation\n",
    "\n",
    "Data augmentation is a crucial technique for improving model generalisation and performance, especially when working with limited datasets. Our augmentation function applies various transformations to the training data to artificially increase the diversity of the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b4f9f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augmentation(df: pd.DataFrame, img_path: Path, output_path: Path, transform: A.Compose, num_augmented:int = 3) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Applies Albumentations transform multiple times to each image, \n",
    "    saves the augmented versions and combines the new metadata with the original.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        DataFrame with 'filename' and 'label' columns.\n",
    "    img_path : Path\n",
    "        Path to images folder.\n",
    "    output_path : Path\n",
    "        Path to save augmented images.\n",
    "    transform : albumentations.Compose\n",
    "        The transform pipeline for data augmentation.\n",
    "    num_augmented : int\n",
    "        Number of augmented versions per image.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        New combined DataFrame with filenames and labels of augmented images.\n",
    "    \"\"\"\n",
    "    # Ensure the output directory exists\n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "    new_records = []\n",
    "\n",
    "    # Iterate through each row in the DataFrame\n",
    "    for _, row in df.iterrows():\n",
    "        filename = row['image_id']\n",
    "        label = row['malignant']\n",
    "\n",
    "        image = Image.open(f\"{img_path}/{filename}\").convert(\"RGB\")\n",
    "        image_np = np.array(image)\n",
    "\n",
    "        # Apply the transformation multiple times to create augmented images\n",
    "        for i in range(num_augmented):\n",
    "            augmented = transform(image=image_np)['image']\n",
    "\n",
    "            new_filename = f\"{os.path.splitext(filename)[0]}_aug{i}.png\"\n",
    "            save_path = os.path.join(output_path, new_filename)\n",
    "            Image.fromarray(augmented).save(save_path)\n",
    "\n",
    "            new_records.append({'image_id': new_filename, 'malignant': label})\n",
    "    \n",
    "    # Create a DataFrame from the new records\n",
    "    augmented_df = pd.DataFrame(new_records)\n",
    "\n",
    "    print(\"Sample of augmented data:\")\n",
    "    print(augmented_df.head())\n",
    "    print('\\n\\n')\n",
    "\n",
    "    # Return combined original and augmented data\n",
    "    return pd.concat([train_df, augmented_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a285036d",
   "metadata": {},
   "source": [
    "# Create Datasets\n",
    "\n",
    "The `create_datasets()` function creates Skin Dataset objects for training, validation, and testing applying data transformations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d66ee0d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_datasets(dataframes: tuple, data_dir: Path, augmented_image_path: Path, resize: tuple) -> tuple:\n",
    "    \"\"\"\n",
    "    Create datasets for training, validation, and testing. Uses various transformations as defined in this project.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dataframes : tuple\n",
    "        A tuple containing three DataFrames: (train_df, val_df, test_df).\n",
    "    data_dir : Path\n",
    "        Path to the data directory.\n",
    "    augmented_image_path : Path\n",
    "        Path to the directory where augmented images are stored.\n",
    "    resize : tuple\n",
    "        Tuple specifying the size to which images should be resized (height, width).\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    tuple of SkinDataset\n",
    "        A tuple containing the training, validation, and test datasets.\n",
    "    \"\"\"\n",
    "    train_df, val_df, test_df = dataframes\n",
    "\n",
    "    # Initialise transformations\n",
    "    train_transform = transformations(resize=resize)\n",
    "    test_transform = get_test_transforms(resize=resize)\n",
    "    augment_transform = transformations(resize=resize, for_augmentation=True)\n",
    "    combined_train_df = augmentation(train_df, image_path, augmented_image_path, augment_transform)\n",
    "\n",
    "    # Create datasets\n",
    "    train_dataset = SkinDataset(combined_train_df, data_dir, transform=train_transform)\n",
    "    val_dataset = SkinDataset(val_df, data_dir, transform=test_transform)\n",
    "    test_dataset = SkinDataset(test_df, data_dir, transform=test_transform)\n",
    "\n",
    "    # Return the datasets\n",
    "    return train_dataset, val_dataset, test_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44303c27",
   "metadata": {},
   "source": [
    "# Store Datasets\n",
    "\n",
    "We store the datasets as PyTorch tensors to avoid redundant preprocessing during model training and evaluation. Each dataset (training, validation, and testing) is stored with:\n",
    "- Image tensors (already transformed and normalised)\n",
    "- Label tensors (malignant or benign)\n",
    "- Filenames for traceability and explainability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "be4dd256",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store as PyTorch tensors\n",
    "def store_dataset(dataset: Dataset, name: str, output_dir: Path) -> None:\n",
    "  \"\"\" \n",
    "  Store a PyTorch dataset as tensors in a specified directory.\n",
    "  Parameters\n",
    "  ----------\n",
    "  dataset : Dataset\n",
    "      The dataset to be stored.\n",
    "  name : str\n",
    "      Name of the dataset to be saved.\n",
    "  output_dir : Path\n",
    "      Directory where the dataset will be saved.\n",
    "  \"\"\"\n",
    "\n",
    "  images = []\n",
    "  labels = []\n",
    "  filenames = []\n",
    "\n",
    "  for i in range(len(dataset)):\n",
    "    image, label, filename = dataset[i]\n",
    "    images.append(image)\n",
    "    labels.append(label)\n",
    "    filenames.append(filename)\n",
    "  \n",
    "  # Convert to tensors\n",
    "  images = torch.stack(images)\n",
    "  labels = torch.tensor(labels)\n",
    "  filenames = np.array(filenames)\n",
    "  \n",
    "  # Save tensors\n",
    "  torch.save({\n",
    "    'images': images,\n",
    "    'labels': labels,\n",
    "    'filenames': filenames\n",
    "  }, output_dir / f'{name}_dataset.pt')\n",
    "  \n",
    "  print(f\"Saved {name} dataset with {len(dataset)} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfec784b",
   "metadata": {},
   "source": [
    "# Execute Create and Store Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b63668af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample of augmented data:\n",
      "          image_id  malignant\n",
      "0  000005_aug0.png          1\n",
      "1  000005_aug1.png          1\n",
      "2  000005_aug2.png          1\n",
      "3  000188_aug0.png          0\n",
      "4  000188_aug1.png          0\n",
      "\n",
      "\n",
      "\n",
      "Saved train dataset with 1572 samples\n",
      "Saved val dataset with 131 samples\n",
      "Saved test dataset with 132 samples\n"
     ]
    }
   ],
   "source": [
    "resize = (384, 384)\n",
    "\n",
    "# Create datasets\n",
    "train_dataset, val_dataset, test_dataset = create_datasets(\n",
    "  (train_df, val_df, test_df),\n",
    "  data_dir,\n",
    "  augmented_image_path,\n",
    "  resize=resize\n",
    ")\n",
    "\n",
    "# Create directory for saving loaders if it doesn't exist\n",
    "os.makedirs(processed_data_dir, exist_ok=True)\n",
    "\n",
    "# Save all datasets\n",
    "store_dataset(train_dataset, 'train', processed_data_dir)\n",
    "store_dataset(val_dataset, 'val', processed_data_dir)\n",
    "store_dataset(test_dataset, 'test', processed_data_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
