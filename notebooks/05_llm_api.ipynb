{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "badf8af3",
   "metadata": {},
   "source": [
    "## LLM API call using OpenAI API\n",
    "\n",
    "The purpose of this notebook is to demonstrate the use of LLM API calls for increasing understandibility of the XAI methods in the context of CNN skin cancer prediction. In each individual API call, the LLM model is supplied with a set of thorough instructions aimed at making its outputs more accessible to non-technical audiences. \n",
    "\n",
    "**Prerequisites:**\n",
    "\n",
    "Please note, this LLM pipeline uses data output by the ``04_xai_pipeline.ipynb`` notebook, therefore, please make sure the files are available in relevant folders.\n",
    "For the analysis, you also need to supply your own sample that needs to be stored in ``user_inputs`` folder."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e940ab0b",
   "metadata": {},
   "source": [
    "### Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f1bf645",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI, APIError, APIConnectionError, RateLimitError\n",
    "from pathlib import Path\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import base64\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import Literal, Optional, Annotated, List\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "451b1ba6",
   "metadata": {},
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113fbb67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths to the relevant folders\n",
    "root_dir = Path.cwd().parent\n",
    "user_inputs_dir = root_dir / 'user_inputs'\n",
    "results_dir = root_dir / 'results'\n",
    "xai_output_dir = results_dir / 'xai_output'\n",
    "\n",
    "# Define relevant input data paths\n",
    "sample_path = user_inputs_dir / 'user_sample1.jpg'\n",
    "sample_probs_path = xai_output_dir / 'model_output.csv'\n",
    "xai_gradcam_output_path = xai_output_dir / 'user_sample1_xai_gradcam.png'\n",
    "xai_shap_output_path = xai_output_dir / 'user_sample1_xai_shap.png'\n",
    "xai_influence_output_path = xai_output_dir / 'user_sample1_influence_function.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bfbeae9",
   "metadata": {},
   "source": [
    "### OpenAI client setup\n",
    "\n",
    "In order to use OpenAI API you will need an OPENAI_API_KEY. You then need to create .env file with your own key, e.g.:\n",
    "\n",
    "``OPENAI_API_KEY=\"YOUR_OPENAI_API_KEY\" ``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0508791c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define .env file path\n",
    "env_path = root_dir / '.env'\n",
    "\n",
    "# Load the .env variable (API key)\n",
    "load_dotenv(dotenv_path=env_path, \n",
    "            override=True) # Outputs True if variables could be loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cabcdfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access the loaded OpenAI API key\n",
    "key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Construct client instance using the key\n",
    "client = OpenAI(api_key=key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d7a7d5b",
   "metadata": {},
   "source": [
    "### Loading the data\n",
    "\n",
    "In this step we load the outputs from the 04_xai_pipeline.ipynb notebook and encode the images to the format supported by OpenAI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d32d7d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to encode the images to base64 byte objects in string format\n",
    "def encode_image(image_path):\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        return base64.b64encode(image_file.read()).decode(\"utf-8\")\n",
    "\n",
    "# encode the xai output images\n",
    "xai_gradcam_enc = encode_image(xai_gradcam_output_path)\n",
    "xai_shap_enc = encode_image(xai_shap_output_path)\n",
    "\n",
    "# encode the user sample\n",
    "user_sample_enc = encode_image(sample_path)\n",
    "\n",
    "# Read in the sample probabilities output by the model\n",
    "with open(sample_probs_path, \"r\",  encoding=\"utf-8\") as f:\n",
    "    sample_probs = f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7513ae0",
   "metadata": {},
   "source": [
    "### Instructions\n",
    "\n",
    "In constructing the instructions for LLM, we have followed OpenAI's best prompting practices available [here](https://cookbook.openai.com/examples/gpt4-1_prompting_guide).\n",
    "\n",
    "Among the others, a few-shot learning technique was used in order for the model to learn patterns present in expected outputs.\n",
    "\n",
    "The instructions are stored in ``data/llm`` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3875af33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the instructions\n",
    "with open(os.path.join(os.getcwd(), \"../data/llm/llm_instructions.md\"), \"r\", encoding=\"utf-8\") as f:\n",
    "    instructions = f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34299166",
   "metadata": {},
   "source": [
    "### Influence Functions Statistics\n",
    "\n",
    "LLMs are prone to inaccuracy when analysing datasets, which raises particular concerns in clinical contexts. In our project, one of the XAI method outputs—Influence Functions—is supplied as a .csv file. To minimise accuracy issues, the function below analyses the dataset, and these statistics will be fed to the LLM in the subsequent step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d9a8875",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def influence_functions_stats(filepath : Path, predicted_class : str) -> tuple[float, float, float | None]:\n",
    "    \"\"\"\n",
    "    Calculate statistics for the Influence Functions data. In particular, the function calculates:\n",
    "    - percentage of the influential training cases that share their ground truth with CNN-predicted class\n",
    "    - percentage of the influential training cases that don't share their ground truth with CNN-predicted class\n",
    "    - percentage of the ground-truth-aligned cases that were misclassified during training\n",
    "\n",
    "    Arguments:\n",
    "    filepath (pathlib.Path): path to the CSV dataset containing output of the Ifluential Function\n",
    "    predicted_class (str): CNN predicted class for a user sample\n",
    "\n",
    "    Returns:\n",
    "    A tuple of containing statistics for the 3 calculations (as in the description).\n",
    "    \"\"\"\n",
    "\n",
    "    # Read in the influence functions data\n",
    "    influence_data = pd.read_csv(filepath)\n",
    "\n",
    "    # Filter for influential training cases that share ground truth with predicted class\n",
    "    alligned_groundtruth = influence_data[influence_data['ground_truth'] == predicted_class]\n",
    "\n",
    "    # Set default values\n",
    "    groundtruth_alignment_percentage, groundtruth_misalignment_percentage, misclassified_percentage = 0, 100, None\n",
    "\n",
    "    # Check for the count of alligned cases\n",
    "    if len(alligned_groundtruth) > 0:\n",
    "        # Calculate the percentage of influential training cases that share ground truth with predicted class\n",
    "        groundtruth_alignment_percentage = (len(alligned_groundtruth) / len(influence_data['ground_truth'])) * 100\n",
    "\n",
    "        # Calculate the percentage of the aligned cases that were misclassified during training\n",
    "        misclassified_percentage = round((len(alligned_groundtruth[alligned_groundtruth[\"ground_truth\"] != alligned_groundtruth[\"prediction\"]]) / len(alligned_groundtruth)) * 100, 2)\n",
    "\n",
    "    # Calculate the percentage of influential training cases whose ground truth does NOT match the predicted class\n",
    "    groundtruth_misalignment_percentage = 100 - groundtruth_alignment_percentage\n",
    "\n",
    "    return groundtruth_alignment_percentage, groundtruth_misalignment_percentage, misclassified_percentage\n",
    "\n",
    "# Establish the CNN-predicted class\n",
    "sample_data = pd.read_csv(sample_probs_path)\n",
    "predicted_class = str(sample_data.loc[sample_data['confidence'].idxmax(), 'class'])\n",
    "\n",
    "# Compute the Influence Functions stats\n",
    "influence_stats = influence_functions_stats(filepath=xai_influence_output_path, \n",
    "                                            predicted_class=predicted_class)\n",
    "\n",
    "print(\n",
    "    f\"Prediction: {predicted_class}\", \n",
    "    f\"\\nGround-truth-aligned cases: {influence_stats[0]}%\", \n",
    "    f\"\\nGround-truth misalignment percentage: {influence_stats[1]}%\",\n",
    "    f\"\\nMisclassified percentage: {influence_stats[2]}%\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d205bd",
   "metadata": {},
   "source": [
    "### LLM API call\n",
    "\n",
    "We use a flagship model from OpenAI, GPT-4.1 (model snapshot: 2025-04-14). According to the company's documentation, it is highly capable at complex task while expressing strict adherance to instructions.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adac7d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    response = client.responses.create(\n",
    "        model=\"gpt-4.1-2025-04-14\",\n",
    "        input=[\n",
    "            {\n",
    "                \"role\": \"developer\",\n",
    "                \"content\" : instructions\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    { \n",
    "                        \"type\": \"input_text\",\n",
    "                        \"text\": str(sample_probs) }, # sample probabilities\n",
    "                    { \n",
    "                        \"type\": \"input_text\",\n",
    "                        \"text\": str(influence_stats)}, # influence functions stats\n",
    "                        \n",
    "                    {\n",
    "                        \"type\": \"input_image\",\n",
    "                        \"image_url\": f\"data:image/png;base64,{xai_gradcam_enc}\", # GradCAM output, base64-encoded PNG file\n",
    "                        \"detail\": \"auto\"\n",
    "                    },\n",
    "                    {\n",
    "                        \"type\": \"input_image\",\n",
    "                        \"image_url\": f\"data:image/png;base64,{xai_shap_enc}\", # SHAP output, base64-encoded PNG file\n",
    "                        \"detail\": \"auto\"\n",
    "                    },\n",
    "                    {\n",
    "                        \"type\": \"input_image\",\n",
    "                        \"image_url\": f\"data:image/jpg;base64,{user_sample_enc}\", # Original user sample, base64-encoded JPG file\n",
    "                        \"detail\": \"auto\"\n",
    "                    },\n",
    "\n",
    "                ],\n",
    "            }\n",
    "        ],\n",
    "        temperature=0.0\n",
    "    )\n",
    "\n",
    "    # Print the LLM interpretation\n",
    "    print(response.output_text)\n",
    "\n",
    "# Handle potential errors\n",
    "except TimeoutError as e:\n",
    "    print(f\"The LLM API call encountered TimeoutError: {e}\")\n",
    "\n",
    "except openai.APIError as e:\n",
    "    print(f\"OpenAI API error: {e}\")    \n",
    "\n",
    "except openai.APIConnectionError as e:\n",
    "    print(f\"Connection error: {e}\")\n",
    "    \n",
    "except openai.RateLimitError as e:\n",
    "    print(f\"Rate limit exceeded: {e}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Unexpected error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4665825e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and display xai images for context\n",
    "img1 = Image.open(sample_path)\n",
    "img2 = Image.open(xai_gradcam_output_path)\n",
    "img3 = Image.open(xai_shap_output_path)\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(12, 4))\n",
    "axes[0].imshow(img1)\n",
    "axes[0].axis('off')\n",
    "axes[0].set_title('Original Sample')\n",
    "axes[1].imshow(img2)\n",
    "axes[1].axis('off')\n",
    "axes[1].set_title('GradCAM Visualisation')\n",
    "axes[2].imshow(img3)\n",
    "axes[2].axis('off')\n",
    "axes[2].set_title('SHAP Visualisation')\n",
    "\n",
    "# Adjust layout to prevent overlap\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41881756",
   "metadata": {},
   "source": [
    "### Write the LLM interpretaton to .txt file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab82102",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define path for the LLM output\n",
    "llm_output_path = xai_output_dir / 'llm_output.txt'\n",
    "\n",
    "with open(file=llm_output_path, mode=\"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(response.output_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4427cd0",
   "metadata": {},
   "source": [
    "### Parse LLM Output for Quantitative Analysis\n",
    "\n",
    "The call below parses the LLM interpretation while extracting cruicial insights to enable a quantitative analysis against the original CNN prediction. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb1c534",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Prediction(BaseModel):\n",
    "    prediction: Literal['Benign', 'Malignant'] = Field(\n",
    "        description=\"'Benign' for when the AI analysis suggests low or moderately low concern for malignancy; 'Malignant' for when the AI analysis indicates high or moderately high concern for malignancy. \" \\\n",
    "        \"For borderline predictions, extract the class that is mentioned in the Confidence Level section.\"\n",
    "        )\n",
    "    confidence: Annotated[float, Field(\n",
    "        description=\"Model confidence, as indicated in the Confidence Level section. 2 decimal places.\"\n",
    "        )]\n",
    "    influential_cases_percentage: Annotated[int, Field(\n",
    "        description=\"Influence Functions: Percentage of the most influential training cases that were diagnosed with the same class as the class predicted by the model.\" \\\n",
    "        \"For borderline predictions, the class predicted by the model is indicated in the Confidence Level section.\"\n",
    "    )]\n",
    "\n",
    "try:\n",
    "    extraction = client.responses.parse(\n",
    "        model=\"gpt-4o-2024-08-06\",\n",
    "        input=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are an expert at structured data extraction. You will be given unstructured text from AI analysis and you should convert it into the given structure.\",\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\", \n",
    "                \"content\": response.output_text\n",
    "                },\n",
    "        ],\n",
    "        text_format=Prediction,\n",
    "    )\n",
    "\n",
    "    extracted_data = extraction.output_parsed.model_dump()\n",
    "\n",
    "# Handle potential errors\n",
    "except TimeoutError as e:\n",
    "    print(f\"The LLM API call encountered TimeoutError: {e}\")\n",
    "\n",
    "except openai.APIError as e:\n",
    "    print(f\"OpenAI API error: {e}\")    \n",
    "\n",
    "except openai.APIConnectionError as e:\n",
    "    print(f\"Connection error: {e}\")\n",
    "    \n",
    "except openai.RateLimitError as e:\n",
    "    print(f\"Rate limit exceeded: {e}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Unexpected error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e0e8fe5",
   "metadata": {},
   "source": [
    "The code below parses the LLM interpretation while searching for keywords indicating a 'borderline' prediction. According to llm_instructons.md we expect the LLM to interpret as *borderline* all predictions output by the CNN that are between `>= 0.5 and < 0.6`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76dccaf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define custom function for extracting the borderline prediction status\n",
    "def borderline_parser(llm_output : str, key_words: List[str]) -> bool:\n",
    "    \"\"\"\n",
    "    Parse the LLM output and search for the key words to confirm if the given prediction \n",
    "    was interpreted as \"borderline\". \n",
    "\n",
    "    Arguments:\n",
    "    llm_output (str): original LLM interpretation of XAI methods in the skin cancer prediction\n",
    "    key_words (List[str]): key words to match against the LLM output\n",
    "\n",
    "    Returns:\n",
    "    A bool value for the presence or absence of the \"borderline\" prediction status.\n",
    "    \"\"\"\n",
    "\n",
    "    # Narrow-down parsing focus if exact headng is present in the LLM output\n",
    "    if '**Confidence Level**' in llm_output:\n",
    "        start_indx = 0\n",
    "        end_indx = llm_output.find(\"**Confidence Level**\")\n",
    "        llm_output = llm_output[start_indx : end_indx].lower()\n",
    "    else:\n",
    "        llm_output = llm_output.lower()\n",
    "\n",
    "    borderline = False\n",
    "    key_words = [word.lower() for word in key_words]\n",
    "\n",
    "    # Parse for the key words (with lowered case)\n",
    "    for word in key_words:\n",
    "        if word in llm_output:\n",
    "            borderline = True\n",
    "            break\n",
    "\n",
    "    return borderline\n",
    "\n",
    "# Implement the function and update extracted_data with the function's finding\n",
    "key_words = [\"borderline\"]\n",
    "borderline_status = borderline_parser(llm_output=response.output_text, \n",
    "                                      key_words=key_words)\n",
    "extracted_data[\"borderline\"] = borderline_status\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63445030",
   "metadata": {},
   "source": [
    "### Write the parsed data to the .csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fca0601",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define path for the extracted data \n",
    "parsed_llm_output_path = xai_output_dir / 'parsed_llm_output.csv'\n",
    "\n",
    "# Write extracted_data to a csv file for quantitative analysis\n",
    "with open(file=parsed_llm_output_path, mode='w', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(extracted_data.keys())\n",
    "    writer.writerow(extracted_data.values())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
